{
  "best_global_step": 2808,
  "best_metric": 0.8910550458715596,
  "best_model_checkpoint": "outputs/sst2_lora/checkpoint-2808",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 3510,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07122507122507123,
      "grad_norm": 1.028915286064148,
      "learning_rate": 9.860398860398861e-05,
      "loss": 0.5878,
      "step": 50
    },
    {
      "epoch": 0.14245014245014245,
      "grad_norm": 0.6079034805297852,
      "learning_rate": 9.717948717948718e-05,
      "loss": 0.3658,
      "step": 100
    },
    {
      "epoch": 0.21367521367521367,
      "grad_norm": 0.5790413618087769,
      "learning_rate": 9.575498575498575e-05,
      "loss": 0.3491,
      "step": 150
    },
    {
      "epoch": 0.2849002849002849,
      "grad_norm": 1.5125925540924072,
      "learning_rate": 9.433048433048434e-05,
      "loss": 0.3092,
      "step": 200
    },
    {
      "epoch": 0.3561253561253561,
      "grad_norm": 1.1763521432876587,
      "learning_rate": 9.290598290598292e-05,
      "loss": 0.3054,
      "step": 250
    },
    {
      "epoch": 0.42735042735042733,
      "grad_norm": 1.1808393001556396,
      "learning_rate": 9.148148148148149e-05,
      "loss": 0.2953,
      "step": 300
    },
    {
      "epoch": 0.4985754985754986,
      "grad_norm": 1.4030377864837646,
      "learning_rate": 9.005698005698005e-05,
      "loss": 0.3136,
      "step": 350
    },
    {
      "epoch": 0.5698005698005698,
      "grad_norm": 0.790729284286499,
      "learning_rate": 8.863247863247864e-05,
      "loss": 0.2833,
      "step": 400
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 1.2472277879714966,
      "learning_rate": 8.720797720797721e-05,
      "loss": 0.2929,
      "step": 450
    },
    {
      "epoch": 0.7122507122507122,
      "grad_norm": 0.6449771523475647,
      "learning_rate": 8.578347578347578e-05,
      "loss": 0.2998,
      "step": 500
    },
    {
      "epoch": 0.7834757834757835,
      "grad_norm": 0.772128701210022,
      "learning_rate": 8.435897435897436e-05,
      "loss": 0.2933,
      "step": 550
    },
    {
      "epoch": 0.8547008547008547,
      "grad_norm": 0.6443220973014832,
      "learning_rate": 8.293447293447294e-05,
      "loss": 0.2897,
      "step": 600
    },
    {
      "epoch": 0.9259259259259259,
      "grad_norm": 0.528678834438324,
      "learning_rate": 8.150997150997152e-05,
      "loss": 0.2703,
      "step": 650
    },
    {
      "epoch": 0.9971509971509972,
      "grad_norm": 1.0312200784683228,
      "learning_rate": 8.008547008547009e-05,
      "loss": 0.2799,
      "step": 700
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8784403669724771,
      "eval_loss": 0.2838935852050781,
      "eval_runtime": 0.4525,
      "eval_samples_per_second": 1927.119,
      "eval_steps_per_second": 22.1,
      "step": 702
    },
    {
      "epoch": 1.0683760683760684,
      "grad_norm": 0.7622479796409607,
      "learning_rate": 7.866096866096867e-05,
      "loss": 0.2839,
      "step": 750
    },
    {
      "epoch": 1.1396011396011396,
      "grad_norm": 1.1376234292984009,
      "learning_rate": 7.723646723646724e-05,
      "loss": 0.2686,
      "step": 800
    },
    {
      "epoch": 1.210826210826211,
      "grad_norm": 0.6938855648040771,
      "learning_rate": 7.581196581196581e-05,
      "loss": 0.2842,
      "step": 850
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.8352020382881165,
      "learning_rate": 7.438746438746439e-05,
      "loss": 0.2715,
      "step": 900
    },
    {
      "epoch": 1.3532763532763532,
      "grad_norm": 0.7470853328704834,
      "learning_rate": 7.296296296296296e-05,
      "loss": 0.2595,
      "step": 950
    },
    {
      "epoch": 1.4245014245014245,
      "grad_norm": 0.6084613800048828,
      "learning_rate": 7.153846153846155e-05,
      "loss": 0.2519,
      "step": 1000
    },
    {
      "epoch": 1.4957264957264957,
      "grad_norm": 1.0741876363754272,
      "learning_rate": 7.011396011396012e-05,
      "loss": 0.2568,
      "step": 1050
    },
    {
      "epoch": 1.566951566951567,
      "grad_norm": 0.9076615571975708,
      "learning_rate": 6.86894586894587e-05,
      "loss": 0.2658,
      "step": 1100
    },
    {
      "epoch": 1.6381766381766383,
      "grad_norm": 0.8616065382957458,
      "learning_rate": 6.726495726495727e-05,
      "loss": 0.2586,
      "step": 1150
    },
    {
      "epoch": 1.7094017094017095,
      "grad_norm": 0.9834470748901367,
      "learning_rate": 6.584045584045584e-05,
      "loss": 0.254,
      "step": 1200
    },
    {
      "epoch": 1.7806267806267806,
      "grad_norm": 0.9769219756126404,
      "learning_rate": 6.441595441595442e-05,
      "loss": 0.253,
      "step": 1250
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 1.2581456899642944,
      "learning_rate": 6.299145299145299e-05,
      "loss": 0.2491,
      "step": 1300
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 1.1010087728500366,
      "learning_rate": 6.156695156695156e-05,
      "loss": 0.2591,
      "step": 1350
    },
    {
      "epoch": 1.9943019943019942,
      "grad_norm": 0.777753472328186,
      "learning_rate": 6.0142450142450144e-05,
      "loss": 0.2461,
      "step": 1400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8853211009174312,
      "eval_loss": 0.279213547706604,
      "eval_runtime": 0.4437,
      "eval_samples_per_second": 1965.113,
      "eval_steps_per_second": 22.536,
      "step": 1404
    },
    {
      "epoch": 2.0655270655270654,
      "grad_norm": 0.6048810482025146,
      "learning_rate": 5.8717948717948725e-05,
      "loss": 0.2467,
      "step": 1450
    },
    {
      "epoch": 2.1367521367521367,
      "grad_norm": 0.9304835796356201,
      "learning_rate": 5.72934472934473e-05,
      "loss": 0.2572,
      "step": 1500
    },
    {
      "epoch": 2.207977207977208,
      "grad_norm": 0.8053237199783325,
      "learning_rate": 5.586894586894588e-05,
      "loss": 0.254,
      "step": 1550
    },
    {
      "epoch": 2.2792022792022792,
      "grad_norm": 0.7094884514808655,
      "learning_rate": 5.4444444444444446e-05,
      "loss": 0.2342,
      "step": 1600
    },
    {
      "epoch": 2.3504273504273505,
      "grad_norm": 0.7142154574394226,
      "learning_rate": 5.301994301994302e-05,
      "loss": 0.249,
      "step": 1650
    },
    {
      "epoch": 2.421652421652422,
      "grad_norm": 1.3919882774353027,
      "learning_rate": 5.159544159544159e-05,
      "loss": 0.265,
      "step": 1700
    },
    {
      "epoch": 2.492877492877493,
      "grad_norm": 0.8098378777503967,
      "learning_rate": 5.0170940170940174e-05,
      "loss": 0.2435,
      "step": 1750
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 0.974608302116394,
      "learning_rate": 4.874643874643875e-05,
      "loss": 0.245,
      "step": 1800
    },
    {
      "epoch": 2.635327635327635,
      "grad_norm": 1.8996057510375977,
      "learning_rate": 4.732193732193733e-05,
      "loss": 0.2433,
      "step": 1850
    },
    {
      "epoch": 2.7065527065527064,
      "grad_norm": 1.1691389083862305,
      "learning_rate": 4.5897435897435895e-05,
      "loss": 0.2452,
      "step": 1900
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 1.357469081878662,
      "learning_rate": 4.4472934472934475e-05,
      "loss": 0.2402,
      "step": 1950
    },
    {
      "epoch": 2.849002849002849,
      "grad_norm": 0.8750458359718323,
      "learning_rate": 4.304843304843305e-05,
      "loss": 0.2344,
      "step": 2000
    },
    {
      "epoch": 2.92022792022792,
      "grad_norm": 1.0933384895324707,
      "learning_rate": 4.162393162393163e-05,
      "loss": 0.2385,
      "step": 2050
    },
    {
      "epoch": 2.9914529914529915,
      "grad_norm": 1.2463243007659912,
      "learning_rate": 4.0199430199430196e-05,
      "loss": 0.2379,
      "step": 2100
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8887614678899083,
      "eval_loss": 0.2710103690624237,
      "eval_runtime": 0.4388,
      "eval_samples_per_second": 1987.432,
      "eval_steps_per_second": 22.792,
      "step": 2106
    },
    {
      "epoch": 3.0626780626780628,
      "grad_norm": 0.9860913753509521,
      "learning_rate": 3.877492877492878e-05,
      "loss": 0.232,
      "step": 2150
    },
    {
      "epoch": 3.133903133903134,
      "grad_norm": 1.049501895904541,
      "learning_rate": 3.735042735042735e-05,
      "loss": 0.2157,
      "step": 2200
    },
    {
      "epoch": 3.2051282051282053,
      "grad_norm": 1.0662963390350342,
      "learning_rate": 3.592592592592593e-05,
      "loss": 0.237,
      "step": 2250
    },
    {
      "epoch": 3.2763532763532766,
      "grad_norm": 0.8048452734947205,
      "learning_rate": 3.45014245014245e-05,
      "loss": 0.2447,
      "step": 2300
    },
    {
      "epoch": 3.347578347578348,
      "grad_norm": 0.9459336996078491,
      "learning_rate": 3.307692307692308e-05,
      "loss": 0.2349,
      "step": 2350
    },
    {
      "epoch": 3.4188034188034186,
      "grad_norm": 1.709133267402649,
      "learning_rate": 3.165242165242165e-05,
      "loss": 0.2334,
      "step": 2400
    },
    {
      "epoch": 3.49002849002849,
      "grad_norm": 0.9677367210388184,
      "learning_rate": 3.0227920227920232e-05,
      "loss": 0.233,
      "step": 2450
    },
    {
      "epoch": 3.561253561253561,
      "grad_norm": 0.8255635499954224,
      "learning_rate": 2.8803418803418803e-05,
      "loss": 0.2397,
      "step": 2500
    },
    {
      "epoch": 3.6324786324786325,
      "grad_norm": 0.9510881304740906,
      "learning_rate": 2.737891737891738e-05,
      "loss": 0.2195,
      "step": 2550
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 1.1642690896987915,
      "learning_rate": 2.5954415954415957e-05,
      "loss": 0.2323,
      "step": 2600
    },
    {
      "epoch": 3.774928774928775,
      "grad_norm": 1.0580681562423706,
      "learning_rate": 2.452991452991453e-05,
      "loss": 0.2328,
      "step": 2650
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 0.8579995036125183,
      "learning_rate": 2.3105413105413108e-05,
      "loss": 0.227,
      "step": 2700
    },
    {
      "epoch": 3.9173789173789175,
      "grad_norm": 1.0431455373764038,
      "learning_rate": 2.168091168091168e-05,
      "loss": 0.2288,
      "step": 2750
    },
    {
      "epoch": 3.9886039886039883,
      "grad_norm": 2.0007967948913574,
      "learning_rate": 2.025641025641026e-05,
      "loss": 0.2268,
      "step": 2800
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8910550458715596,
      "eval_loss": 0.26955950260162354,
      "eval_runtime": 0.4504,
      "eval_samples_per_second": 1935.869,
      "eval_steps_per_second": 22.2,
      "step": 2808
    },
    {
      "epoch": 4.05982905982906,
      "grad_norm": 1.0508803129196167,
      "learning_rate": 1.8831908831908832e-05,
      "loss": 0.2321,
      "step": 2850
    },
    {
      "epoch": 4.131054131054131,
      "grad_norm": 1.0800528526306152,
      "learning_rate": 1.740740740740741e-05,
      "loss": 0.2274,
      "step": 2900
    },
    {
      "epoch": 4.202279202279202,
      "grad_norm": 1.168558120727539,
      "learning_rate": 1.5982905982905983e-05,
      "loss": 0.2236,
      "step": 2950
    },
    {
      "epoch": 4.273504273504273,
      "grad_norm": 0.8931103944778442,
      "learning_rate": 1.455840455840456e-05,
      "loss": 0.2232,
      "step": 3000
    },
    {
      "epoch": 4.344729344729345,
      "grad_norm": 1.0768969058990479,
      "learning_rate": 1.3133903133903134e-05,
      "loss": 0.219,
      "step": 3050
    },
    {
      "epoch": 4.415954415954416,
      "grad_norm": 0.9745847582817078,
      "learning_rate": 1.170940170940171e-05,
      "loss": 0.2196,
      "step": 3100
    },
    {
      "epoch": 4.487179487179487,
      "grad_norm": 1.3035447597503662,
      "learning_rate": 1.0284900284900286e-05,
      "loss": 0.2338,
      "step": 3150
    },
    {
      "epoch": 4.5584045584045585,
      "grad_norm": 1.0921612977981567,
      "learning_rate": 8.860398860398861e-06,
      "loss": 0.2158,
      "step": 3200
    },
    {
      "epoch": 4.62962962962963,
      "grad_norm": 0.9447367191314697,
      "learning_rate": 7.435897435897436e-06,
      "loss": 0.2366,
      "step": 3250
    },
    {
      "epoch": 4.700854700854701,
      "grad_norm": 1.2766618728637695,
      "learning_rate": 6.011396011396011e-06,
      "loss": 0.2095,
      "step": 3300
    },
    {
      "epoch": 4.772079772079772,
      "grad_norm": 0.7877339720726013,
      "learning_rate": 4.586894586894587e-06,
      "loss": 0.2294,
      "step": 3350
    },
    {
      "epoch": 4.843304843304844,
      "grad_norm": 1.2300585508346558,
      "learning_rate": 3.1623931623931626e-06,
      "loss": 0.2217,
      "step": 3400
    },
    {
      "epoch": 4.914529914529915,
      "grad_norm": 0.8682277202606201,
      "learning_rate": 1.7378917378917378e-06,
      "loss": 0.2329,
      "step": 3450
    },
    {
      "epoch": 4.985754985754986,
      "grad_norm": 1.9630800485610962,
      "learning_rate": 3.133903133903134e-07,
      "loss": 0.2338,
      "step": 3500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8899082568807339,
      "eval_loss": 0.26822343468666077,
      "eval_runtime": 0.3907,
      "eval_samples_per_second": 2231.855,
      "eval_steps_per_second": 25.595,
      "step": 3510
    }
  ],
  "logging_steps": 50,
  "max_steps": 3510,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4159901288308896.0,
  "train_batch_size": 96,
  "trial_name": null,
  "trial_params": null
}
